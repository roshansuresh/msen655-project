{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Import statements\n",
    "# For generating dummy training data\n",
    "from pyDOE2 import *\n",
    "import numpy as np\n",
    "# For Abaqus FEA evaluation\n",
    "from subprocess import Popen, PIPE\n",
    "# For Neural Network\n",
    "import csv\n",
    "from keras.models import load_model\n",
    "# For gaussian process regressors\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from math import sin, cos, pi, radians\n",
    "# For Optimization\n",
    "import copy\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization\n",
    "- This notebook details the implementation of a modified version of the multifidelity constrained Bayesian Optimization algorithm from: Ghoreishi, Seyede Fatemeh, and Douglas Allaire. \"Multi-information source constrained Bayesian optimization.\" Structural and Multidisciplinary Optimization 59, no. 3 (2019): 977-991.\n",
    "- The algorithm is first tested on a benchmark problem taken from the above mentioned paper to make sure the algorithm is working satisfactorily\n",
    "- After validation using the test problem, the algorithm is used on the composite plate problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function Definitions for Composite Plate problem\n",
    "- The model functions for the composite plate problem are defined below\n",
    "- The design parameters are fibre radius (r_f), fibre_angle (theta_f) and matrix Young's Modulus (E_m)\n",
    "- The objective to maximize is the buckling load (P_cr)\n",
    "- Three models are available: a high fidelity FEA model (using Abaqus Python Scipting), a low fidelity analytical model and a low fidelity Neural Network (trained using FEA model evaluations)\n",
    "- The constraint is that the volume fraction (v_f) must be less than 0.75.\n",
    "- Two simplified versions of this constraint are available, termed g_1(x) and g_2(x) respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the model functions for Composite Plate problem\n",
    "## Analytical Model (Low Fidelity Model 1)\n",
    "def analytical(x,n_eigen):\n",
    "    # Here l,w,t are the length, width and thickness of the plate and E_f is the fibre Young's Modulus\n",
    "    # These are defined as global variables\n",
    "    r_f = x[0] # in mm\n",
    "    theta_f = x[1] # in degrees\n",
    "    E_m = x[2] # in GPa\n",
    "    P_cr = []\n",
    "    poisson_ratio = 0.3\n",
    "    v_f = volume_fraction(l,w,t,x)\n",
    "    ## Rule of Mixtures\n",
    "    E_effective = (E_f*v_f + (1-v_f)*E_m)*1e3 # Converting to N/mm^2\n",
    "    D = E_effective*t**3/(12*(1-poisson_ratio**2)) # Flexural Rigidity\n",
    "    for i in range(n_eigen):\n",
    "        m = i+1\n",
    "        n = 1\n",
    "        P_cr.append(D*(pi*l/m)**2*((m/l)**2+(n/w)**2)**2)\n",
    "    return P_cr\n",
    "    \n",
    "# Volume Fraction\n",
    "def volume_fraction(length,width,thickness,x_design):\n",
    "    r_f = x_design[0]\n",
    "    theta_f = x_design[1]\n",
    "    v_total = length*width*thickness\n",
    "    l_fibre_shortest = length/(6*cos(radians(theta_f)))\n",
    "    l_fibre_med = 2*l_fibre_shortest\n",
    "    l_fibre_longest = 3*l_fibre_shortest\n",
    "    vol_fibres = pi*(r_f**2)*(2*l_fibre_shortest + 2*l_fibre_med + l_fibre_longest)\n",
    "    vol_total = length*width*thickness\n",
    "    vol_frac = vol_fibres/vol_total\n",
    "    return vol_frac\n",
    "    \n",
    "## Neural Network (Lower Fidelity Model 2)\n",
    "network = load_model('Buckling_Neural_Net_norm.h5')\n",
    "# Load the normalization constants from the csv file\n",
    "with open('normalization_constants.csv',newline='')as csvfile:\n",
    "    data = [row for row in csv.reader(csvfile)]\n",
    "    data_row = data[1]\n",
    "    data_mean_float = [float(data_row[0]), float(data_row[1]), float(data_row[2])]\n",
    "    data_var_float = [float(data_row[3]), float(data_row[4]), float(data_row[5])]\n",
    "\n",
    "def neural_net(x):\n",
    "    # The output of the neural network is scaled using the normalization constants to give the actual prediction\n",
    "    P_cr_norm = network.predict(x.reshape(1,-1))\n",
    "    P_cr = P_cr_norm*np.sqrt(data_var_float) + data_mean_float\n",
    "    return P_cr\n",
    "\n",
    "## Abaqus FEA model (Ground Truth)\n",
    "def abaqus_fea(x, job_num):\n",
    "    r_f = x[0] # in mm\n",
    "    theta_f = x[1] # in degrees\n",
    "    E_m = x[2]*1000 # in N/mm^2\n",
    "    \n",
    "    # Running the abaqus job for the given parameters as a subprocess through the command line\n",
    "    sys_command = ['abaqus','cae','noGUI=abaqus_fea_macro.py','--',str(r_f),str(theta_f),str(E_m),str(job_num)]\n",
    "    process = Popen(sys_command, stdout=PIPE, stderr=PIPE, cwd=r'H:/Desktop/MSEN 655 - Material Design Studio/python code/final bayesian optimization run',shell=True)\n",
    "    process.wait()\n",
    "    stdout, stderr = process.communicate()\n",
    "    output_string = stdout.decode(\"utf-8\")\n",
    "    \n",
    "    ## Reading the outputs string to extract the eigenvalue information\n",
    "    # The output string has the form \"Eigenvalue One: value Endone, Eigenvalue Two: value Endtwo, Eigenvalue Three: value Endthree\"\n",
    "    # More information on the extraction specifics is given in Neural_net_training_kfold.py\n",
    "    # If the abaqus evaluation fails because of meshing issues and \"Error\" is thrown, the design is evaluated using the analytical model instead\n",
    "    if (output_string.find('Error') == -1):\n",
    "        Eigen_1_pos_start = output_string.find('One') + 6\n",
    "        Eigen_1_pos_end = output_string.find('Endone') - 1\n",
    "        Eigen_2_pos_start = output_string.find('Two') + 6\n",
    "        Eigen_2_pos_end= output_string.find('Endtwo') - 1\n",
    "        Eigen_3_pos_start = output_string.find('Three') + 8\n",
    "        Eigen_3_pos_end = output_string.find('Endthree') - 1\n",
    "    \n",
    "        buckling_load_e1 = output_string[Eigen_1_pos_start:Eigen_1_pos_end-1]\n",
    "        buckling_load_e2 = output_string[Eigen_2_pos_start:Eigen_2_pos_end-1]\n",
    "        buckling_load_e3 = output_string[Eigen_3_pos_start:Eigen_3_pos_end-1]\n",
    "        \n",
    "        buckling_eigen_1 = float(buckling_load_e1[2:])\n",
    "        if (buckling_load_e2.find('E+') != -1):\n",
    "            buckling_eigen_2 = float(buckling_load_e2[1:])\n",
    "        else:\n",
    "            buckling_eigen_2 = float(buckling_load_e2[2:])\n",
    "            \n",
    "        if (buckling_load_e3.find('E+') != -1):\n",
    "            buckling_eigen_3 = float(buckling_load_e3[1:-1])\n",
    "        else:\n",
    "            buckling_eigen_3 = float(buckling_load_e3[2:-2])\n",
    "    \n",
    "        P_cr = [buckling_eigen_1, buckling_eigen_2, buckling_eigen_3]\n",
    "    else:\n",
    "        P_cr = analytical(x, 3)\n",
    "    \n",
    "    process.kill()\n",
    "    return P_cr\n",
    "\n",
    "## High fidelity Constraint Model\n",
    "def constraint_hf(x, vf_limit):\n",
    "    vf_x = volume_fraction(l,w,t,x)\n",
    "    constraint = vf_x - vf_limit\n",
    "    return constraint\n",
    "\n",
    "## First Lower Fidelity Constraint Model\n",
    "def constraint_lf1(x, vf_limit):\n",
    "    r_f = x[0]\n",
    "    theta_f = x[1]\n",
    "    const_g1 = r_f**2/(1000*cos(radians(theta_f))) - vf_limit\n",
    "    return const_g1\n",
    "\n",
    "## Second Lower Fidelity Constraint Model\n",
    "def constraint_lf2(x, vf_limit):\n",
    "    r_f = x[0]\n",
    "    theta_f = x[1]\n",
    "    const_g2 = (r_f**2/(1000*sin(radians(theta_f))) + 0.1) - vf_limit\n",
    "    return const_g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function Definitions for Test problem\n",
    "- The model functions for the test problem are defined below\n",
    "- The design space is one-dimensional\n",
    "- The objective to be maximized\n",
    "- Three objective models are available: a high fidelity model and two low fidelity models \n",
    "- Three constraint models are available: a high fidelity model and two low fidelity models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the model functions for Test problem\n",
    "## High fidelity objective model\n",
    "def gt_obj(x):\n",
    "    y_gt = -(1.4 - 3*x)*(sin(18*x))\n",
    "    return y_gt\n",
    "\n",
    "## Low fidelity objective model 1\n",
    "def low_fid_obj1(x):\n",
    "    y_f1 = -(1.6 - 3*x)*(sin(18*x))\n",
    "    return y_f1\n",
    "\n",
    "## Low fidelity objective model 2\n",
    "def low_fid_obj2(x):\n",
    "    y_f2 = -(1.8 - 3*x)*sin(18*x + 0.1)\n",
    "    return y_f2\n",
    "\n",
    "## High fidelity constraint model\n",
    "def constraint_hf_test(x):\n",
    "    y_c_gt = x**2 - 1.2\n",
    "    return y_c_gt\n",
    "\n",
    "## Low fidelity constraint model 1\n",
    "def constraint_lf1_test(x):\n",
    "    y_c_lf1 = (x - 0.001)**2 - 1.2\n",
    "    return y_c_lf1\n",
    "\n",
    "## Low fidelity constraint model 2\n",
    "def constraint_lf2_test(x):\n",
    "    y_c_lf2 = (x + 0.02)**2 - 1.2\n",
    "    return y_c_lf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "- The functions defined below are represent operations performed frequently in the optimization algorithm\n",
    "- The Utility functions are defined in a generalised manner so as to apply to both the test problem and the composite plate problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some useful functions for the algorithm\n",
    "## GPR training given design set and response\n",
    "def gp_train(x,y,n_x,x_max,rand_state):\n",
    "    x_dim = len(x_max)\n",
    "    len_scale = []\n",
    "    for ia in range(x_dim):\n",
    "        len_scale.append(x_max[ia]*2/n_x)\n",
    "    kernel = Matern(length_scale=len_scale, nu=2.5)\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, random_state=rand_state).fit(x,y)\n",
    "    return gpr\n",
    "\n",
    "## Computing fidelity variance (model discrepancy)\n",
    "def fidelity_variance(x,gp_gt,gp1,gp2):\n",
    "    # The fidelity variance is computed over a dataset different from the GP training datasets\n",
    "    y_gt = gp_gt.predict(x)\n",
    "    y_lf1 = gp1.predict(x)\n",
    "    y_lf2 = gp2.predict(x)\n",
    "    fid_var1 = np.mean(np.subtract(y_gt, y_lf1))**2\n",
    "    fid_var2 = np.mean(np.subtract(y_gt, y_lf2))**2\n",
    "    fid_var_vec = [fid_var1, fid_var2]\n",
    "    return fid_var_vec\n",
    "\n",
    "## Winkler Fusion\n",
    "def Winkler_fusion(x, gp_1, gp_2, sigma_f1, sigma_f2, x_max, get_gp=False):\n",
    "    n_des = len(x)\n",
    "    \n",
    "    gp1_means = np.zeros(n_des)\n",
    "    gp1_stds = np.zeros(n_des)\n",
    "    gp2_means = np.zeros(n_des)\n",
    "    gp2_stds = np.zeros(n_des)\n",
    "    gp_means = np.zeros([n_des,2])\n",
    "    gp_vars = np.zeros([n_des,2])\n",
    "    \n",
    "    # Mean and std predictions at the given designs using the two GPs\n",
    "    [gp1_means, gp1_stds] = gp_1.predict(x, return_std=True)\n",
    "    [gp2_means, gp2_stds] = gp_2.predict(x, return_std=True)\n",
    "    gp_means = np.column_stack((gp1_means, gp2_means))\n",
    "    \n",
    "    # Appending the model discrepancy values to the GP variances\n",
    "    var_1 = gp1_stds**2 + sigma_f1\n",
    "    var_2 = gp2_stds**2 + sigma_f2\n",
    "    gp_vars = np.column_stack((var_1, var_2))\n",
    "    \n",
    "    # The fusion process\n",
    "    rho_tilde = np.zeros([n_des,2,2])\n",
    "    rho = np.zeros([n_des,2,2])\n",
    "    covar = np.zeros([n_des,2,2])\n",
    "    mean_winkler = np.zeros(n_des)\n",
    "    var_winkler = np.zeros(n_des)\n",
    "    \n",
    "    for i in range(n_des):\n",
    "        # Compute rho_tilde matrix for current design sample\n",
    "        rho_tilde_x = np.zeros([2,2])\n",
    "        mean_vec = gp_means[i,:]\n",
    "        var_vec = gp_vars[i,:]\n",
    "        for j1 in range(2):\n",
    "            for k1 in range(2):\n",
    "                mean_j = mean_vec[j1]\n",
    "                mean_k = mean_vec[k1]\n",
    "                var_j = var_vec[j1]\n",
    "                var_k = var_vec[k1]\n",
    "                rho_tilde_x[j1,k1] = np.sqrt(var_j)/(np.sqrt((mean_j - mean_k)**2 + var_j))\n",
    "                \n",
    "        # Compute correlation matrix for current design sample\n",
    "        rho_x = np.zeros([2,2])\n",
    "        for j2 in range(2):\n",
    "            for k2 in range(2):\n",
    "                var_j = var_vec[j2]\n",
    "                var_k = var_vec[k2]\n",
    "                rho_x[j2,k2] = (var_k/(var_j + var_k))*rho_tilde_x[j2,k2] + (var_j/(var_j + var_k))*rho_tilde_x[k2,j2]\n",
    "                \n",
    "        # Compute covariance matrix for current design sample\n",
    "        #rho_x = rho[i,:,:]\n",
    "        covar_x = np.zeros([2,2])                                             \n",
    "        for j3 in range(2):\n",
    "            for k3 in range(2):\n",
    "                std_j = np.sqrt(var_vec[j3])\n",
    "                std_k = np.sqrt(var_vec[k3])\n",
    "                covar_x[j3,k3] = rho_x[j3,k3]*std_j*std_k\n",
    "                \n",
    "        # Compute Winkler Means and Variances\n",
    "        e_vec = np.ones(2)\n",
    "        mean_winkler[i] = (np.linalg.multi_dot([np.transpose(e_vec), np.linalg.inv(covar_x), mean_vec]))/(np.linalg.multi_dot([np.transpose(e_vec), np.linalg.inv(covar_x), e_vec]))\n",
    "        var_winkler[i] = 1/(np.linalg.multi_dot([np.transpose(e_vec), np.linalg.inv(covar_x), e_vec]))\n",
    "        rho_tilde[i,:,:] = rho_tilde_x\n",
    "        rho[i,:,:] = rho_x\n",
    "        covar[i,:,:] = covar_x\n",
    "        \n",
    "    # Train the fused GPR (if required)\n",
    "    if (get_gp):\n",
    "        gp_fused = gp_train(x,mean_winkler,n_des,x_max,n_des)\n",
    "    else:\n",
    "        gp_fused = None\n",
    "    \n",
    "    return mean_winkler, var_winkler, gp_fused\n",
    "\n",
    "## Extracting feasible design points using the fused constraint GP\n",
    "def filter_designs(x,gp_constraint_fused):\n",
    "    n_des = len(x)\n",
    "    const_mean = np.zeros(n_des)\n",
    "    const_std = np.zeros(n_des)\n",
    "    x_feas = []\n",
    "    [const_mean, const_std] = gp_constraint_fused.predict(x, return_std=True)\n",
    "    for i in range(n_des):\n",
    "        if (const_mean[i] + 3*const_std[i] <= 0):\n",
    "            x_feas.append(x[i,:])\n",
    "    \n",
    "    return np.array(x_feas)\n",
    "\n",
    "## Expected Improvement computation\n",
    "def exp_improv(fused_means, fused_vars, y_best_current):\n",
    "    n_des = len(fused_means)\n",
    "    EI = np.zeros(n_des)\n",
    "    for i in range(n_des):\n",
    "        mean_i = fused_means[i]\n",
    "        var_i = fused_vars[i]\n",
    "        if (var_i == 0):\n",
    "            EI[i] = 0\n",
    "        else:\n",
    "            pdf_val = norm.pdf(mean_i, y_best_current, var_i)\n",
    "            cdf_val = norm.pdf(mean_i, y_best_current, var_i)\n",
    "            EI[i] = (mean_i - y_best_current)*cdf_val + var_i*pdf_val\n",
    "    ei = np.amax(EI)\n",
    "    return ei\n",
    "\n",
    "## Information Gain computation\n",
    "def info_gain(fused_means_prior, fused_vars_prior, fused_means_post, fused_vars_post, x_dim):\n",
    "    n_des = len(fused_means_prior)\n",
    "    kl_d = np.zeros(n_des)\n",
    "    for i in range(n_des):\n",
    "        kl_d[i] = ((fused_vars_prior[i]/fused_vars_post[i]) + ((fused_means_post[i] - fused_means_prior[i])**2/fused_vars_post[i]) - x_dim + np.log(fused_vars_post[i]/fused_vars_prior[i]))/2\n",
    "    ig = np.sum(kl_d)/n_des\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Optimization Algorithm\n",
    "- The cells below show the implementation of the multifidelity source constrained Bayesian Optimization algorithm\n",
    "- The algorithm is implemented in function form for easy test runs using a mathematical benchmark problem taken from: Ghoreishi, Seyede Fatemeh, and Douglas Allaire. \"Multi-information source constrained Bayesian optimization.\" Structural and Multidisciplinary Optimization 59, no. 3 (2019): 977-991.\n",
    "- The Optimization function (called MFCBO for Multi Fidelity Constrained Bayesian Optimization) is defined in a generalised manner for easy deployment for the test problem and the composite plate problem. \n",
    "- The function is defined to accomodate different maximization problems with two low fidelity objective and constraint models. \n",
    "- Future improvements include further generalization of the function to incorporate different number of objective and constraint low fidelity models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCBO(n_xvar, x_range, n_gt, n_f, n_const_gt, n_const, n_alt, n_test, cost_f, cost_c, max_cost, vf_limit, problem):\n",
    "    n_fmod = len(n_f) # Number of lower fidelity objective models\n",
    "    n_cmod = len(n_const) # Number of lower fidelity constraint models\n",
    "    xmax = []\n",
    "    for i in range(n_xvar):\n",
    "        xmax.append(x_range[i][1])\n",
    "        \n",
    "    # Generated design samples for objectives and constraints\n",
    "    x_f = {}\n",
    "    y_f = {}\n",
    "    x_c = {}\n",
    "    y_c = {}\n",
    "    gps_c = {}\n",
    "    gps_f = {}\n",
    "    # Costs of evaluation\n",
    "    cost_f_gt = cost_f[0]\n",
    "    cost_f_lf1 = cost_f[1]\n",
    "    cost_f_lf2 = cost_f[2]\n",
    "    cost_c_gt = cost_c[0]\n",
    "    cost_c_lf1 = cost_c[1]\n",
    "    cost_c_lf2 = cost_c[2]\n",
    "    \n",
    "    ## Projecting the designs from Latin Hypercube Sampling to the appropriate design space\n",
    "    def sample_project(x, x_range, n_xvar):\n",
    "        # x = [a_val, b_val, c_val]\n",
    "        n_samp = len(x)\n",
    "        \n",
    "        x_projected = np.zeros([n_samp, n_xvar])\n",
    "        for i in range(n_xvar):\n",
    "            x_i_lower = x_range[i][0]\n",
    "            x_i_upper = x_range[i][1]\n",
    "            #x_i_projected = x[:,i]*(x_i_upper - x_i_lower) + np.ones(n_samp)*x_i_lower\n",
    "            for j in range(n_samp):\n",
    "                x_projected[j,i] = x[j,i]*(x_i_upper - x_i_lower) + x_i_lower\n",
    "    \n",
    "        return x_projected\n",
    "    \n",
    "    ## Define a job number (as a requirement for the abaqus fea function and to keep a track of the number of ground truth evaluations)\n",
    "    job_num_gtup = 0 # Number of abaqus evaluations for updating the ground truth GP\n",
    "\n",
    "    ######################### STEP 1 - Initialization #########################\n",
    "    ## Generate design samples for constraints\n",
    "    x_const = lhs(n_xvar, samples=n_const_gt, criterion='maximin')\n",
    "    x_const_proj = sample_project(x_const, x_range, n_xvar)\n",
    "    for i2 in range(n_cmod):\n",
    "        x_ci = lhs(n_xvar, samples=n_const[i2], criterion='maximin')\n",
    "        x_ci_proj = sample_project(x_ci, x_range, n_xvar)\n",
    "        x_c[str(i2)] = x_ci_proj\n",
    "\n",
    "    ## Generate design samples for the ground truth and lower fidelity model GPs\n",
    "    x_gt = lhs(n_xvar, samples=n_gt, criterion='maximin')\n",
    "    x_gt_proj = sample_project(x_gt, x_range, n_xvar)\n",
    "    for i3 in range(n_fmod):\n",
    "        x_fi = lhs(n_xvar, samples=n_f[i3], criterion='maximin')\n",
    "        x_fi_proj = sample_project(x_fi, x_range, n_xvar)\n",
    "        x_f[str(i3)] = x_fi_proj\n",
    "    \n",
    "    def init_iter(x_c_gt, y_c_gt_i, x_constraints, y_constraints_i, is_query_const, x_f_gt, y_f_gt_i, x_objectives, y_objectives_i, is_query_obj, n_c_gt, n_constraints, n_f_gt, n_objectives, gp_hf_c, gp_hf_f, cost_current, gt_update, iter_num, job_num_gtup):\n",
    "        ## Compute reference constraint values for the training samples based on the problem\n",
    "        if (problem == 'composite_plate'):\n",
    "            for i4 in range(n_cmod):\n",
    "                x_c_current = x_constraints[str(i4)]\n",
    "                if (iter_num == 0): # for the first iteration, evaluate all designs \n",
    "                    y_c_current = np.zeros(n_constraints[i4])\n",
    "                    # Reference constraint values for lower fidelity model 1 GP\n",
    "                    if (i4 == 0): \n",
    "                        for i5 in range(n_constraints[i4]):\n",
    "                            y_c_current[i5] = constraint_lf1(x_c_current[i5,:], vf_limit)\n",
    "                            cost_current += cost_c_lf1\n",
    "                    # Reference constraint values for lower fidelity model 2 GP\n",
    "                    elif (i4 == 1): \n",
    "                        for i5 in range(n_constraints[i4]):\n",
    "                            y_c_current[i5] = constraint_lf2(x_c_current[i5,:], vf_limit)\n",
    "                            cost_current += cost_c_lf2\n",
    "                else:\n",
    "                    continue\n",
    "                y_c[str(i4)] = y_c_current\n",
    "                    \n",
    "            if (iter_num != 0): # for subsequent iterations, simply evaluate last added design and append\n",
    "                if (is_query_const == 0):\n",
    "                    x_c_current = x_constraints[str(is_query_const)]\n",
    "                    y_c_noupd = y_constraints_i[str(is_query_const+1)]\n",
    "                    y_c_updated = constraint_lf1(x_c_current[-1], vf_limit)\n",
    "                    cost_current += cost_c_lf1\n",
    "                    y_c_i = list(y_constraints_i[str(is_query_const)])\n",
    "                    y_c_i.append(y_c_updated)\n",
    "                    y_c_current = y_c_i\n",
    "                    y_c[str(is_query_const)] = y_c_current\n",
    "                    y_c[str(is_query_const+1)] = y_c_noupd\n",
    "                elif (is_query_const == 1):\n",
    "                    x_c_current = x_constraints[str(is_query_const)]\n",
    "                    y_c_noupd = y_constraints_i[str(is_query_const-1)]\n",
    "                    y_c_updated = constraint_lf2(x_c_current[-1], vf_limit)\n",
    "                    cost_current += cost_c_lf2\n",
    "                    y_c_i = list(y_constraints_i[str(is_query_const)])\n",
    "                    y_c_i.append(y_c_updated)\n",
    "                    y_c_current = y_c_i\n",
    "                    y_c[str(is_query_const)] = y_c_current\n",
    "                    y_c[str(is_query_const-1)] = y_c_noupd\n",
    "                          \n",
    "        elif (problem == 'test'):\n",
    "            for i4 in range(n_cmod):\n",
    "                x_c_current = x_constraints[str(i4)]\n",
    "                if (iter_num == 0): # for the first iteration, evaluate all designs \n",
    "                    y_c_current = np.zeros(n_constraints[i4])\n",
    "                    # Reference constraint values for lower fidelity model 1 GP\n",
    "                    if (i4 == 0): \n",
    "                        for i5 in range(n_constraints[i4]):\n",
    "                            y_c_current[i5] = constraint_lf1_test(x_c_current[i5,:])\n",
    "                            cost_current += cost_c_lf1\n",
    "                    # Reference constraint values for lower fidelity model 2 GP\n",
    "                    elif (i4 == 1): \n",
    "                        for i5 in range(n_constraints[i4]):\n",
    "                            y_c_current[i5] = constraint_lf2_test(x_c_current[i5,:])\n",
    "                            cost_current += cost_c_lf2\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "                y_c[str(i4)] = y_c_current\n",
    "                    \n",
    "            if (iter_num != 0): # for subsequent iterations, simply evaluate last added design and append\n",
    "                if (is_query_const == 0):\n",
    "                    x_c_current = x_constraints[str(is_query_const)]\n",
    "                    y_c_noupd = y_constraints_i[str(is_query_const+1)]\n",
    "                    y_c_updated = constraint_lf1_test(x_c_current[-1])\n",
    "                    cost_current += cost_c_lf1\n",
    "                    y_c_i = list(y_constraints_i[str(is_query_const)])\n",
    "                    y_c_i.append(y_c_updated)\n",
    "                    y_c_current = y_c_i\n",
    "                    y_c[str(is_query_const)] = y_c_current\n",
    "                    y_c[str(is_query_const+1)] = y_c_noupd\n",
    "                elif (is_query_const == 1):\n",
    "                    x_c_current = x_constraints[str(is_query_const)]\n",
    "                    y_c_noupd = y_constraints_i[str(is_query_const-1)]\n",
    "                    y_c_updated = constraint_lf2_test(x_c_current[-1])\n",
    "                    cost_current += cost_c_lf2\n",
    "                    y_c_i = list(y_constraints_i[str(is_query_const)])\n",
    "                    y_c_i.append(y_c_updated)\n",
    "                    y_c_current = y_c_i\n",
    "                    y_c[str(is_query_const)] = y_c_current\n",
    "                    y_c[str(is_query_const-1)] = y_c_noupd\n",
    "                    \n",
    "        ## Train the constraint GPs \n",
    "        for i6 in range(n_cmod):\n",
    "            x_c_current = x_constraints[str(i6)]\n",
    "            y_c_current = y_c[str(i6)]\n",
    "            gp_lfi_c = gp_train(x_c_current, y_c_current, n_constraints[i6], xmax, i6)\n",
    "            gps_c[str(i6)] = gp_lfi_c\n",
    "            \n",
    "        ## Updating Constraint Ground Truth GP (if required)\n",
    "        if (gt_update):\n",
    "            if (problem == 'composite_plate'):\n",
    "                # Reference constraint values for ground truth GP\n",
    "                if (iter_num == 0):\n",
    "                    y_const = np.zeros(n_c_gt)\n",
    "                    for i7 in range(n_c_gt):\n",
    "                        y_const[i7] = constraint_hf(x_c_gt[i7,:], vf_limit)\n",
    "                        cost_current += cost_c_gt\n",
    "                elif (iter_num != 0):\n",
    "                    y_const_updated = constraint_hf(x_c_gt[-1], vf_limit)\n",
    "                    cost_current += cost_c_gt\n",
    "                    y_c_gt_list = list(y_c_gt_i)\n",
    "                    y_c_gt_list.append(y_const_updated)\n",
    "                    y_const = y_c_gt_list\n",
    "            elif (problem == 'test'):\n",
    "                # Reference constraint values for ground truth GP\n",
    "                if (iter_num == 0):\n",
    "                    y_const = np.zeros(n_c_gt)\n",
    "                    for i7 in range(n_c_gt):\n",
    "                        y_const[i7] = constraint_hf_test(x_c_gt[i7,:])\n",
    "                        cost_current += cost_c_gt\n",
    "                elif (iter_num != 0):\n",
    "                    y_const_updated = constraint_hf_test(x_c_gt[-1])\n",
    "                    cost_current += cost_c_gt\n",
    "                    y_c_gt_list = list(y_c_gt_i)\n",
    "                    y_c_gt_list.append(y_const_updated)\n",
    "                    y_const = y_c_gt_list\n",
    "            # Train the new ground truth constraint GP\n",
    "            gp_gt_c = gp_train(x_c_gt, y_const, n_c_gt, xmax, n_c_gt)\n",
    "        else:\n",
    "            gp_gt_c = copy.copy(gp_hf_c)\n",
    "            y_const = copy.copy(y_c_gt_i)\n",
    "    \n",
    "        # Compute model discrepancy values for the two lower fidelity constraint models\n",
    "        x_fid = lhs(n_xvar, samples=n_c_gt, criterion='maximin')\n",
    "        x_fid_proj = sample_project(x_fid, x_range, n_xvar)\n",
    "        gp_lf1_c = gps_c['0']\n",
    "        gp_lf2_c = gps_c['1']\n",
    "        fid_var_lf_c = fidelity_variance(x_fid_proj, gp_gt_c, gp_lf1_c, gp_lf2_c)\n",
    "        fid_var_lf1_c = fid_var_lf_c[0]\n",
    "        fid_var_lf2_c = fid_var_lf_c[1]\n",
    "    \n",
    "        ## Generate reference objectives for the feasible training samples based on the problem\n",
    "        if (problem == 'composite_plate'):\n",
    "            for i8 in range(n_fmod):\n",
    "                x_f_current = x_objectives[str(i8)]\n",
    "                if (iter_num == 0): # for the first iteration, evaluate all designs \n",
    "                    y_f_current = np.zeros(n_objectives[i8])\n",
    "                    # Reference objectives for analytical model GP\n",
    "                    if (i8 == 0): \n",
    "                        y_f1_3eig = np.zeros(3)\n",
    "                        for i9 in range(n_objectives[i8]):\n",
    "                            y_f1_3eig = analytical(x_f_current[i9,:], 3)\n",
    "                            y_f_current[i9] = y_f1_3eig[0] + 0.5*y_f1_3eig[1] + 0.25*y_f1_3eig[2]\n",
    "                            cost_current += cost_f_lf1\n",
    "                    # Reference objectives for neural net GP\n",
    "                    elif (i8 == 1): \n",
    "                        y_f2_3eig = np.zeros(3)\n",
    "                        for i9 in range(n_objectives[i8]):\n",
    "                            y_f2_3eig = neural_net(x_f_current[i9,:])\n",
    "                            y_f_current[i9] = y_f2_3eig[0][0] + 0.5*y_f2_3eig[0][1] + 0.25*y_f2_3eig[0][2]\n",
    "                            cost_current += cost_f_lf2\n",
    "                else:\n",
    "                    continue\n",
    "                y_f[str(i8)] = y_f_current\n",
    "                \n",
    "            if (iter_num != 0): # for subsequent iterations, simply evaluate last added design and append\n",
    "                if (is_query_obj == 0):\n",
    "                    x_f_current = x_objectives[str(is_query_obj)]\n",
    "                    y_f_noupd = y_objectives_i[str(is_query_obj+1)]\n",
    "                    y_f_updated = analytical(x_f_current[-1], 3)\n",
    "                    y_f_upd = y_f_updated[0] + 0.5*y_f_updated[1] + 0.25*y_f_updated[2]\n",
    "                    y_f_i = list(y_objectives_i[str(is_query_obj)])\n",
    "                    y_f_i.append(y_f_upd)\n",
    "                    y_f_current = y_f_i\n",
    "                    cost_current += cost_f_lf1\n",
    "                    y_f[str(is_query_obj)] = y_f_current\n",
    "                    y_f[str(is_query_obj+1)] = y_f_noupd\n",
    "                elif (is_query_obj == 1):\n",
    "                    x_f_current = x_objectives[str(is_query_obj)]\n",
    "                    y_f_noupd = y_objectives_i[str(is_query_obj-1)]\n",
    "                    y_f_updated = neural_net(x_f_current[-1])\n",
    "                    y_f_upd = y_f_updated[0][0] + 0.5*y_f_updated[0][1] + 0.25*y_f_updated[0][2]\n",
    "                    y_f_i = list(y_objectives_i[str(is_query_obj)])\n",
    "                    y_f_i.append(y_f_upd)\n",
    "                    y_f_current = y_f_i\n",
    "                    cost_current += cost_f_lf2\n",
    "                    y_f[str(is_query_obj)] = y_f_current\n",
    "                    y_f[str(is_query_obj-1)] = y_f_noupd\n",
    "                \n",
    "        elif (problem == 'test'):\n",
    "            for i8 in range(n_fmod):\n",
    "                x_f_current = x_objectives[str(i8)]\n",
    "                if (iter_num == 0):\n",
    "                    # Reference objectives for lower fidelity model 1 GP\n",
    "                    y_f_current = np.zeros(n_objectives[i8])\n",
    "                    if (i8 == 0):\n",
    "                        for i9 in range(n_objectives[i8]):\n",
    "                            y_f_current[i9] = low_fid_obj1(x_f_current[i9,:])\n",
    "                            cost_current += cost_f_lf1\n",
    "                    # Reference objectives for lower fidelity model 2 GP\n",
    "                    elif (i8 == 1):\n",
    "                        for i9 in range(n_objectives[i8]):\n",
    "                            y_f_current[i9] = low_fid_obj2(x_f_current[i9,:])\n",
    "                            cost_current += cost_f_lf2\n",
    "                else:\n",
    "                    continue\n",
    "                y_f[str(i8)] = y_f_current\n",
    "                \n",
    "            if (iter_num != 0):\n",
    "                if (is_query_obj == 0):\n",
    "                    x_f_current = x_objectives[str(is_query_obj)]\n",
    "                    y_f_noupd = y_objectives_i[str(is_query_obj+1)]\n",
    "                    y_f_updated = low_fid_obj1(x_f_current[-1])\n",
    "                    cost_current += cost_f_lf1\n",
    "                    y_f_i = list(y_objectives_i[str(is_query_obj)])\n",
    "                    y_f_i.append(y_f_updated)\n",
    "                    y_f_current = y_f_i\n",
    "                    y_f[str(is_query_obj)] = y_f_current\n",
    "                    y_f[str(is_query_obj+1)] = y_f_noupd\n",
    "                elif (is_query_obj == 1):\n",
    "                    x_f_current = x_objectives[str(is_query_obj)]\n",
    "                    y_f_noupd = y_objectives_i[str(is_query_obj-1)]\n",
    "                    y_f_updated = low_fid_obj2(x_f_current[-1])\n",
    "                    cost_current += cost_f_lf2\n",
    "                    y_f_i = list(y_objectives_i[str(is_query_obj)])\n",
    "                    y_f_i.append(y_f_updated)\n",
    "                    y_f_current = y_f_i\n",
    "                    y_f[str(is_query_obj)] = y_f_current\n",
    "                    y_f[str(is_query_obj-1)] = y_f_noupd\n",
    "        \n",
    "        ## Train the objective GPs \n",
    "        for i10 in range(n_fmod):\n",
    "            x_f_current = x_objectives[str(i10)]\n",
    "            y_f_current = y_f[str(i10)]\n",
    "            gp_lfi_f = gp_train(x_f_current, y_f_current, n_objectives[i10], xmax, i10)\n",
    "            gps_f[str(i10)] = gp_lfi_f\n",
    "            \n",
    "        ## Updating Objective Ground Truth GP (if required)\n",
    "        if (gt_update):\n",
    "            if (problem == 'composite_plate'):\n",
    "                # Reference objectives for ground truth GP\n",
    "                if (iter_num == 0):\n",
    "                    y_gt_3eig = np.zeros(3)\n",
    "                    y_gt = np.zeros(n_f_gt)\n",
    "                    for i11 in range(n_f_gt):\n",
    "                        y_gt_3eig = abaqus_fea(x_f_gt[i11,:], job_num_gtup)\n",
    "                        y_gt[i11] = y_gt_3eig[0] + 0.5*y_gt_3eig[1] + 0.25*y_gt_3eig[2]\n",
    "                        job_num_gtup += 1\n",
    "                        cost_current += cost_f_gt\n",
    "                else:\n",
    "                    y_gt_3eig_updated = abaqus_fea(x_f_gt[-1], job_num_gtup)\n",
    "                    y_gt_upd = y_gt_3eig_updated[0] + 0.5*y_gt_3eig_updated[1] + 0.25*y_gt_3eig_updated[2]\n",
    "                    job_num_gt_up += 1\n",
    "                    cost_current += cost_f_gt\n",
    "                    y_f_gt_list = list(y_f_gt_i)\n",
    "                    y_f_gt_list.append(y_gt_up)\n",
    "                    y_gt = y_f_gt_list\n",
    "            elif (problem =='test'):\n",
    "                # Reference objectives for ground truth GP\n",
    "                if (iter_num == 0):\n",
    "                    y_gt = np.zeros(n_f_gt)\n",
    "                    for i11 in range(n_f_gt):\n",
    "                        y_gt[i11] = gt_obj(x_gt[i11,:])\n",
    "                        cost_current += cost_f_gt\n",
    "                else:\n",
    "                    y_gt_upd = gt_obj(x_f_gt[-1])\n",
    "                    cost_current += cost_f_gt\n",
    "                    y_f_gt_list = list(y_f_gt_i)\n",
    "                    y_f_gt_list.append(y_gt_upd)\n",
    "                    y_gt = y_f_gt_list\n",
    "            # Train the new objective ground truth GP\n",
    "            gp_gt_f = gp_train(x_f_gt, y_gt, n_f_gt, xmax, n_f_gt)\n",
    "        else:\n",
    "            gp_gt_f = copy.copy(gp_hf_f)\n",
    "            y_gt = copy.copy(y_f_gt_i)\n",
    "        \n",
    "        ## Compute model discrepancies for objective lower fidelity models\n",
    "        gp_lf1_f = gps_f['0']\n",
    "        gp_lf2_f = gps_f['1']\n",
    "        fid_var_lf_f = fidelity_variance(x_fid_proj, gp_gt_f, gp_lf1_f, gp_lf2_f)\n",
    "        \n",
    "        cost_up = copy.copy(cost_current)\n",
    "        \n",
    "        return gp_gt_f, gp_gt_c, gps_f, gps_c, y_gt, y_const, x_f, y_f, n_f, x_constraints, y_c, n_constraints, fid_var_lf_f, fid_var_lf_c, cost_up, job_num_gtup\n",
    "\n",
    "    ######################### STEP 2 - Optimization Loop #########################\n",
    "    ## Initialize the evaluation cost and number of iterations\n",
    "    cost = 0\n",
    "    n_iter = 0\n",
    "    ## Define number of design samples for best design evaluation\n",
    "    n_best_samp = 1000*n_xvar\n",
    "    ## For first iteration\n",
    "    job_num_i = job_num_gtup\n",
    "    gpr_hf_c = None\n",
    "    gpr_hf_f = None\n",
    "    hf_update = True\n",
    "    is_query_f = 0\n",
    "    is_query_c = 0\n",
    "    y_f_best_mean = 0\n",
    "    x_const_gt_init = x_const_proj\n",
    "    y_c_gt_init = np.zeros(n_const_gt)\n",
    "    n_const_gt_init = n_const_gt\n",
    "    x_obj_gt_init = x_gt\n",
    "    y_f_gt_init = np.zeros(n_gt)\n",
    "    n_obj_gt_init = n_gt \n",
    "    x_const_init = x_c\n",
    "    y_const_init = {}\n",
    "    n_const_init = n_const\n",
    "    x_obj_init = x_f\n",
    "    y_f_init = {}\n",
    "    n_obj_init = n_f\n",
    "    x_best_iter = {}\n",
    "    x_best_overall = []\n",
    "    y_best_iter = []\n",
    "    y_best_std_iter = []\n",
    "    y_best_overall = 0\n",
    "    y_best_std_overall = []\n",
    "    cost_iter = []\n",
    "    constraint_best_iter = []\n",
    "    constraint_best_std_iter = []\n",
    "    for i in range(n_cmod):\n",
    "        y_const_init[str(i)] = np.zeros(n_const[i])\n",
    "    for i in range(n_fmod):\n",
    "        y_f_init[str(i)] = np.zeros(n_f[i])\n",
    "    \n",
    "    while(cost <= max_cost):\n",
    "        print('Starting iteration ' + str(n_iter+1))\n",
    "        ## Initiailize iteration\n",
    "        gpr_gt_obj, gpr_gt_const, gps_obj, gps_const, y_obj_gt, y_const_gt, x_obj, y_obj, n_obj, x_const, y_const, n_const, mod_disc_f, mod_disc_c, cost_new, job_gt = init_iter(x_const_gt_init, y_c_gt_init, x_const_init, y_const_init, is_query_c, x_obj_gt_init, y_f_gt_init, x_obj_init, y_f_init, is_query_f, n_const_gt_init, n_const_init, n_obj_gt_init, n_obj_init, gpr_hf_c, gpr_hf_f, cost, hf_update, n_iter, job_num_i)\n",
    "        print('Initialization complete')\n",
    "        ## Generate x_alt, x_test and x_best_samp\n",
    "        x_alt_1 = lhs(n_xvar, samples=n_alt, criterion='maximin')\n",
    "        x_alt = sample_project(x_alt_1, x_range, n_xvar)\n",
    "        x_test_1 = lhs(n_xvar, samples=n_test, criterion='maximin')\n",
    "        x_test = sample_project(x_test_1, x_range, n_xvar)\n",
    "        x_best_samp_1 = lhs(n_xvar, samples=n_best_samp, criterion='maximin')\n",
    "        x_best_samp = sample_project(x_best_samp_1, x_range, n_xvar)\n",
    "        ## Filter the infeasible designs\n",
    "        gpr_c1 = gps_const['0']\n",
    "        gpr_c2 = gps_const['1']\n",
    "        sig_fid_c1 = mod_disc_c[0]\n",
    "        sig_fid_c2 = mod_disc_c[1]\n",
    "        mean_best_c_samp, var_best_c_samp, gp_fused_c = Winkler_fusion(x_test, gpr_c1, gpr_c2, sig_fid_c1, sig_fid_c2, xmax, get_gp=True)\n",
    "        x_alt_feas = filter_designs(x_alt, gp_fused_c)\n",
    "        n_alt_feas = len(x_alt_feas)\n",
    "        x_test_feas = filter_designs(x_test, gp_fused_c)\n",
    "        n_test_feas = len(x_test_feas)\n",
    "        x_best_samp_feas = filter_designs(x_best_samp, gp_fused_c)\n",
    "        n_best_samp_feas = len(x_best_samp_feas)\n",
    "        print('Infeasible designs filtered')\n",
    "        \n",
    "        ## Objective optimization\n",
    "        EI_full = np.zeros([n_alt_feas, n_fmod])\n",
    "        for i in range(n_alt_feas):\n",
    "            ei_alt = np.zeros(n_fmod)\n",
    "            for j in range(n_fmod):\n",
    "                x_alt_current = x_alt_feas[i,:]\n",
    "                gp_f_j = gps_obj[str(j)]\n",
    "                n_samples_alt_i = 10\n",
    "                y_samp_alt = gp_f_j.sample_y(x_alt_current.reshape(1,-1), n_samples=n_samples_alt_i, random_state=1)\n",
    "                ei_samp = np.zeros(n_samples_alt_i)\n",
    "                for k in range(n_samples_alt_i):\n",
    "                    temp_gp_f_fused = None\n",
    "                    x_f_j = x_obj[str(j)]\n",
    "                    y_f_j = list(y_obj[str(j)])\n",
    "                    x_f_j_new = np.vstack((x_f_j, x_alt_current))\n",
    "                    y_f_j.append(y_samp_alt[0][k])\n",
    "                    temp_gp_f_j = gp_train(x_f_j_new, y_f_j, n_obj[j]+1, xmax, k)\n",
    "                    fid_var_f_j = mod_disc_f[j]\n",
    "                    if (j+1 > 1):\n",
    "                        fid_var_f_2 = mod_disc_f[j-1]\n",
    "                        gp_f_2 = gps_obj[str(j-1)]\n",
    "                        mean_gp_f_fused, var_gp_f_fused, temp_gp_f_fused = Winkler_fusion(x_test_feas, gp_f_2, temp_gp_f_j, fid_var_f_2, fid_var_f_j, xmax)\n",
    "                    else:\n",
    "                        fid_var_f_2 = mod_disc_f[j+1]\n",
    "                        gp_f_2 = gps_obj[str(j+1)]\n",
    "                        mean_gp_f_fused, var_gp_f_fused, temp_gp_f_fused = Winkler_fusion(x_test_feas, temp_gp_f_j, gp_f_2, fid_var_f_j, fid_var_f_2, xmax)\n",
    "                    ei_samp[k] = exp_improv(mean_gp_f_fused, var_gp_f_fused, y_best_overall)#y_f_best_mean)\n",
    "                ei_alt[j] = np.mean(ei_samp)\n",
    "            EI_full[i,:] = ei_alt\n",
    "        Ei_f_max = np.zeros(n_fmod)\n",
    "        Ei_f_argmax = np.zeros(n_fmod)\n",
    "        #print(EI_full)\n",
    "        for j2 in range(n_fmod):\n",
    "            Ei_f = EI_full[:,j2]\n",
    "            cost_f_j = cost_f[j2+1]\n",
    "            utility = Ei_f/cost_f_j\n",
    "            Ei_f_max[j2] = np.amax(utility)\n",
    "            Ei_f_argmax[j2] = np.argmax(utility)\n",
    "        is_query_f = np.argmax(Ei_f_max)\n",
    "        x_query_index = Ei_f_argmax[is_query_f]\n",
    "        x_query_f = x_alt_feas[int(x_query_index),:]\n",
    "        print('Objective acquisition function maximization complete')\n",
    "        \n",
    "        ## Constraint Optimization\n",
    "        Ig_full = np.zeros([n_alt_feas, n_cmod])\n",
    "        for i in range(n_alt_feas):\n",
    "            ig_alt = np.zeros(n_cmod)\n",
    "            for j in range(n_cmod):\n",
    "                temp_gp_c_fused_prior = None\n",
    "                x_alt_current = x_alt_feas[i,:]\n",
    "                gp_c_j = gps_const[str(j)]\n",
    "                fid_var_c_j = mod_disc_c[j]\n",
    "                if (j+1 > 1):\n",
    "                    fid_var_c_2 = mod_disc_c[j-1]\n",
    "                    gp_c_2 = gps_const[str(j-1)]\n",
    "                    mean_prior_c_fused, var_prior_c_fused, temp_gp_c_fused_prior = Winkler_fusion(x_test_feas, gp_c_2, gp_c_j, fid_var_c_2, fid_var_c_j, xmax)\n",
    "                else:\n",
    "                    fid_var_c_2 = mod_disc_c[j+1]\n",
    "                    gp_c_2 = gps_const[str(j+1)]\n",
    "                    mean_prior_c_fused, var_prior_c_fused, temp_gp_c_fused_prior = Winkler_fusion(x_test_feas, gp_c_j, gp_c_2, fid_var_c_j, fid_var_c_2, xmax)\n",
    "                n_samples_alt_i = 10\n",
    "                y_samp_alt_c = gp_c_j.sample_y(x_alt_current.reshape(1,-1), n_samples=n_samples_alt_i, random_state=1)\n",
    "                ig_samp = np.zeros(n_samples_alt_i)\n",
    "                for k in range(n_samples_alt_i):\n",
    "                    temp_gp_c_fused = None\n",
    "                    x_c_j = x_const[str(j)]\n",
    "                    y_c_j = list(y_const[str(j)])\n",
    "                    x_c_j_new = np.vstack((x_c_j, x_alt_current))\n",
    "                    y_c_j.append(y_samp_alt_c[0][k])\n",
    "                    temp_gp_c_j = gp_train(x_c_j_new, y_c_j, n_const[j]+1, xmax, k)\n",
    "                    fid_var_c_j = mod_disc_c[j]\n",
    "                    if (j+1 > 1):\n",
    "                        fid_var_c_2 = mod_disc_c[j-1]\n",
    "                        gp_c_2 = gps_const[str(j-1)]\n",
    "                        mean_post_c_fused, var_post_c_fused, temp_gp_c_fused = Winkler_fusion(x_test_feas, gp_c_2, temp_gp_c_j, fid_var_c_2, fid_var_c_j, xmax)\n",
    "                    else:\n",
    "                        fid_var_c_2 = mod_disc_c[j+1]\n",
    "                        gp_c_2 = gps_const[str(j+1)]\n",
    "                        mean_post_c_fused, var_post_c_fused, temp_gp_c_fused = Winkler_fusion(x_test_feas, temp_gp_c_j, gp_c_2, fid_var_c_j, fid_var_c_2, xmax)\n",
    "                    ig_samp[k] = info_gain(mean_prior_c_fused, var_prior_c_fused, mean_post_c_fused, var_post_c_fused, n_xvar)\n",
    "                ig_alt[j] = np.mean(ig_samp)\n",
    "            Ig_full[i,:] = ig_alt\n",
    "        Ig_c_max = np.zeros(n_cmod)\n",
    "        Ig_c_argmax = np.zeros(n_cmod)\n",
    "        for j2 in range(n_cmod):\n",
    "            Ig_c = Ig_full[:,j2]\n",
    "            cost_c_j = cost_c[j2+1]\n",
    "            utility = Ig_c/cost_c_j\n",
    "            Ig_c_max[j2] = np.amax(utility)\n",
    "            Ig_c_argmax[j2] = np.argmax(utility)\n",
    "        is_query_c = np.argmax(Ig_c_max)\n",
    "        x_query_c_index = Ig_c_argmax[is_query_c]\n",
    "        x_query_c = x_alt_feas[int(x_query_c_index),:]\n",
    "        print('Constraint acquisition function maximization complete')\n",
    "        \n",
    "        ##  Update the training datasets for the relevant GPs\n",
    "        # For Objective GP\n",
    "        x_f_is_query = x_obj[str(is_query_f)]\n",
    "        x_f_is_updated = list(x_f_is_query)\n",
    "        x_f_is_updated.append(x_query_f)\n",
    "        x_obj[str(is_query_f)] = copy.copy(x_f_is_updated)\n",
    "        x_obj_init = copy.copy(x_obj)\n",
    "        n_obj_init[is_query_f] = len(x_f_is_updated)\n",
    "        y_f_init = copy.copy(y_obj)\n",
    "        print('Objective query point appended to training dataset for appropriate information source')\n",
    "        \n",
    "        # For Constraint GP\n",
    "        #print(is_query_c)\n",
    "        #print(x_const_proj)\n",
    "        x_c_is_query = x_const[str(is_query_c)]\n",
    "        x_c_is_updated = list(x_c_is_query)\n",
    "        x_c_is_updated.append(x_query_c)\n",
    "        x_const[str(is_query_c)] = copy.copy(x_c_is_updated)\n",
    "        x_const_init = copy.copy(x_const)\n",
    "        n_const_init[is_query_c] = len(x_c_is_updated)\n",
    "        y_const_init = copy.copy(y_const)\n",
    "        print('Constraint query point appended to training dataset for appropriate information source')\n",
    "        \n",
    "        ## Current best design \n",
    "        gpr_f1 = gps_obj['0']\n",
    "        gpr_f2 = gps_obj['1']\n",
    "        sig_fid_f1 = mod_disc_f[0]\n",
    "        sig_fid_f2 = mod_disc_f[1]\n",
    "        mean_test_samp, var_test_samp, gp_f_fuse = Winkler_fusion(x_test_feas, gpr_f1, gpr_f2, sig_fid_f1, sig_fid_f2, xmax, get_gp=True)\n",
    "        [obj_best_mean, obj_best_std] = gp_f_fuse.predict(x_best_samp_feas, return_std=True)\n",
    "        obj_best_cond = obj_best_mean - 3*obj_best_std\n",
    "        x_f_pos = np.argmax(obj_best_cond)\n",
    "        x_f_best = x_best_samp_feas[x_f_pos,:]\n",
    "        y_f_best_mean = obj_best_mean[x_f_pos]\n",
    "        y_f_best_std = obj_best_std[x_f_pos]\n",
    "        if (y_f_best_mean > y_best_overall):\n",
    "            y_best_overall = copy.copy(y_f_best_mean)\n",
    "            y_best_std_overall = copy.copy(y_f_best_std)\n",
    "            x_best_overall = copy.copy(x_f_best)\n",
    "        print('Best design point for current iteration determined')\n",
    "        \n",
    "        ## Evaluate estimated constraint value and uncertainty of best design using fused constraint GP\n",
    "        gpr_c1 = gps_const['0']\n",
    "        gpr_c2 = gps_const['1']\n",
    "        sig_fid_c1 = mod_disc_c[0]\n",
    "        sig_fid_c2 = mod_disc_c[1]\n",
    "        mean_best_c_samp, var_best_c_samp, gp_c_fuse = Winkler_fusion(x_test_feas, gpr_c1, gpr_c2, sig_fid_c1, sig_fid_c2, xmax, get_gp=True)\n",
    "        [const_best_mean, const_best_std] = gp_c_fuse.predict(x_f_best.reshape(1,-1), return_std=True)\n",
    "        constraint_best_iter.append(const_best_mean)\n",
    "        constraint_best_std_iter.append(const_best_std)\n",
    "        print('Constraint for best design point for current iteration estimated')\n",
    "        \n",
    "        ## For Ground Truth GPs (if required)\n",
    "        if (n_iter%10 == 0):\n",
    "            # For Objective\n",
    "            x_gt_updated = list(x_obj_gt_init)\n",
    "            x_gt_updated.append(x_f_best)\n",
    "            x_obj_gt_init = copy.copy(x_gt_updated)\n",
    "            n_obj_gt_init = len(x_gt_updated)\n",
    "            y_f_gt_init = copy.copy(y_obj_gt)\n",
    "            \n",
    "            # For Constraint\n",
    "            x_const_gt_updated = list(x_const_gt_init)\n",
    "            x_const_gt_updated.append(x_f_best)\n",
    "            x_const_gt_init = copy.copy(x_const_gt_updated)\n",
    "            n_const_gt_init = len(x_const_gt_updated)\n",
    "            y_c_gt_init = copy.copy(y_const_gt)\n",
    "            \n",
    "            hf_update = True\n",
    "            print('Ground Truth GPs will be updated in the next iteration')\n",
    "        else:\n",
    "            y_f_gt_init = copy.copy(y_obj_gt)\n",
    "            y_c_gt_init = copy.copy(y_const_gt)\n",
    "            hf_update = False\n",
    "            \n",
    "        ## Increase iteration number and update cost\n",
    "        cost = copy.copy(cost_new)\n",
    "        gpr_hf_c = copy.copy(gpr_gt_const)\n",
    "        gpr_hf_f = copy.copy(gpr_gt_obj)\n",
    "        x_best_iter[str(n_iter)] = x_f_best\n",
    "        y_best_iter.append(y_f_best_mean)\n",
    "        y_best_std_iter.append(y_f_best_std)\n",
    "        cost_iter.append(cost_new)\n",
    "        job_num_i = copy.copy(job_gt)\n",
    "        n_iter += 1\n",
    "    \n",
    "    x_best = x_best_overall\n",
    "    y_best_mean = y_best_overall\n",
    "    y_best_std = y_best_std_overall\n",
    "    print('Optimization concluded after ' + str(n_iter) + ' iterations')\n",
    "    print('The best design obtained is' + str(x_best_overall) + '. Its performance metric is ' + str(y_best_overall) + ' with a standard deviation of ' + str(y_best_std_overall))\n",
    "    \n",
    "    return x_best_iter, y_best_iter, y_best_std_iter, constraint_best_iter, constraint_best_std_iter, cost_iter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Ground Truth GPs will be updated in the next iteration\n",
      "Starting iteration 2\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 3\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 4\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 5\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 6\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 7\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 8\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 9\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 10\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 11\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Ground Truth GPs will be updated in the next iteration\n",
      "Starting iteration 12\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 13\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 14\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 15\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 16\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 17\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 18\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 19\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 20\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 21\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Ground Truth GPs will be updated in the next iteration\n",
      "Starting iteration 22\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 23\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Starting iteration 24\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n",
      "Objective acquisition function maximization complete\n",
      "Constraint acquisition function maximization complete\n",
      "Objective query point appended to training dataset for appropriate information source\n",
      "Constraint query point appended to training dataset for appropriate information source\n",
      "Best design point for current iteration determined\n",
      "Constraint for best design point for current iteration estimated\n",
      "Optimization concluded after 24 iterations\n",
      "The best design obtained is[1.09597337]. Its performance metric is 1.335653648810922 with a standard deviation of 0.007671427014285236\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAdr0lEQVR4nO3de7gcVZnv8e+PECAiEJCAIRATIIAojGCDcpFBuapgIEcMMCqoGBUVwREBwRlgjiMH1MM5es5oBB1AQEUhCYoGiFxGgSE7AZIQRCCA5GK4GQgQIAnv/FHVTGfbu3f1pbprd/8+z7OfrlpdVevt6uq8qbWqVikiMDMzy2q9TgdgZmZDixOHmZnVxYnDzMzq4sRhZmZ1ceIwM7O6rN/pAFptyy23jHHjxnU6DDOzIWXOnDlPR8SoLMt2XeIYN24cfX19nQ7DzGxIkfR41mXdVGVmZnVx4jAzs7o4cZiZWV2cOMzMrC5OHGZmVhcnDjMzq4sTh5mZ1aWj93FIOhz4P8Aw4JKIuKDf+xsClwPvBJ4BJkfEY3nEMu2eJVw080GWrljFNiNHcPphO3PUHmNavk67Ymt0vaJ/piLX1c793a66inwMtbOubvxMzVCnnschaRjwJ+AQYDEwGzguIhZWLHMysHtEfFbSscDRETG51nZLpVLUewPgtHuWcNa181m1eu3rZSOGD+Obk3Yb8AtrZJ3yevUcFM3U067PVK921dNMXe34nor+3Rb5GGqmrnb9BhvRrs9UjaQ5EVHKsmwnm6r2Bh6OiEUR8SrwU2Biv2UmApel078ADpKkVgdy0cwH1/miAFatXstFMx9s6Trlg2LJilUEsGTFKs66dj7T7lnS0noaXa/RuurVrnoaratd31PRv9siH0ON1tXO32Aj2vWZmlVX4pC0nqRNW1T3GOCJivnFaVnVZSJiDfAc8KYqcU2R1Cep76mnnqo7kKUrVtVV3ug6jRwUjdTT6HqN1lWvdtXTaF3t+p6K/t0W+RhqtK52/gYb0a7P1KxBE4ekqyRtKmljYCHwoKTTW1B3tTOH/u1mWZYhIqZGRCkiSqNGZRqjax3bjBxRV3mj6zRyUDRST6PrNVpXvdpVT6N1tet7Kvp3W+RjqNG62vkbbES7PlOzspxx7BoRzwNHATcAY4GPtaDuxcB2FfPbAksHWkbS+sBmwLMtqHsdpx+2MyOGD1unbMTwYZx+2M4tXaeRg6KRehpdr9G66tWuehqtq13fU9G/2yIfQ43W1c7fYCPa9ZmalSVxDJc0nCRxTI+I1S2qezYwQdJ4SRsAxwIz+i0zAzghnf4w8LvIoTf/qD3G8M1JuzFm5AgEjBk5YtDOqEbWaeSgaKSedn6mRrSrnkbratf3VPTvtsjHUKN1tfM32Ih2faZmDXpVlaRTgDOA+4APkpxx/CQi3tN05dIHgItJLsf9UUR8Q9L5QF9EzJC0EXAFsAfJmcaxEbGo1jYbuaqqnYbCpXbm76mbdeN32+6rqrIkjvER8WjFvIAdI+KhuqJqk6InDjOzImr15bi/rJxJm4p+2khgZmY29A1457ikXYC3AZtJmlTx1qbARnkHZmZmxVRryJGdgSOAkcCRFeUrgU/nGZSZmRXXgIkjIqYD0yXtExF3tjEmMzMrsFpNVV+NiAuB4yUd1//9iDgl18jMzKyQajVVPZC++hIlMzN7Xa2mquvT18sGWsbMzHrPoM/jkLQT8BVgXOXyEfG+/MIyM7OiyvIgp2uA7wOXAGsHWdbMzLpclsSxJiL+LfdIzMxsSMhy5/j1kk6WNFrSFuW/3CMzM7NCynLGUR6dtvIZHAFs3/pwzMys6AZNHBExvh2BmJnZ0JDlqqqPVyuPiMtbH46ZmRVdlqaqvSqmNwIOAuYCThxmZj0oS1PVFyvnJW1G8nAlMzPrQVmuqurvJWBCqwMxM7OhIUsfx/UkV1FBkmh2BX6eZ1BmZlZcWfo4vlUxvQZ4PCIW5xSPmZkVXJY+jtvaEYiZmQ0NjfRxmJlZD3PiMDOzujhxmJlZXbJcVbUfcC7wlnR5ARERHqvKzKwHZbmq6lLgNGAOfh6HmVnPy9JU9VxE/CYinoyIZ8p/zVSaDs1+k6SH0tfNqyzzDkl3Srpf0jxJk5up08zMWiNL4rhF0kWS9pG0Z/mvyXrPBGZFxARgVjrf30vAxyPibcDhwMWSRjZZr5mZNSlLU9W70tdSRVkAzTxzfCJwYDp9GXArcEblAhHxp4rppZKeBEYBK5qo18zMmpTlBsD35lDv1hGxLN3+Mklb1VpY0t7ABsAjA7w/BZgCMHbs2BaHamZmlQZMHJI+GhE/kfTlau9HxHdqbVjSzcCbq7x1dj0BShpNMhrvCRHx2gCxTAWmApRKpai2jJmZtUatM46N09dNGtlwRBw80HuSlksanZ5tjAaeHGC5TYFfA+dExF2NxGFmZq01YOKIiB+kr+flUO8MkmeZX5C+Tu+/gKQNgOuAyyPimhxiMDOzBnTqzvELgEMkPQQcks4jqSTpknSZjwAHACdKujf9e0dnwjUzszJFdFeXQKlUir6+vk6HYWY2pEiaExGlwZf0WFVmZlanLGNVbQj8D2Bc5fIRcX5+YZmZWVFluQFwOvAcyVhVr+QbjpmZFV2WxLFtRByeeyRmZjYkZOnjuEPSbrlHYmZmQ0KWM479SS6JfZSkqar8PI7dc43MzMwKKUvieH/uUZiZ2ZCRJXGszFhmZmY9IEsfx1zgKeBPwEPp9KOS5kp6Z57BmZlZ8WRJHL8FPhARW0bEm0iarn4OnAz8/zyDMzOz4smSOEoRMbM8ExE3Ageko9VumFtkZmZWSFn6OJ6VdAbw03R+MvBXScOAqs/HMDOz7pXljON4YFtgGsld5GPTsmEkI9iamVkPyfLo2KeBLw7w9sOtDcfMzIqu1qNjL46IUyVdD/zN2OsR8aFcIzMzs0KqdcZxRfr6rXYEYmZmQ0OtR8fOSV9vK5dJ2hzYLiLmtSE2MzMroEE7xyXdKmlTSVsA9wE/lvSd/EMzM7MiynJV1WYR8TwwCfhxRLwTODjfsMzMrKiyJI71JY0mufT2VznHY2ZmBZclcZwPzAQeiYjZkrYnGbPKzMx6UJb7OK4BrqmYX0TyDHIzM+tBWTrHd5I0S9KCdH53SefkH5qZmRVRlqaqHwJnAasB0ktxj80zKDMzK64sieMNEXF3v7I1eQRjZmbFlyVxPC1pB9JhRyR9GFjWTKWStpB0k6SH0tfNayy7qaQlkr7XTJ1mZtYaWRLH54EfALtIWgKcCnyuyXrPBGZFxARgVjo/kH8BbqvxvpmZtVGWq6oWAQdL2hhYLyJa8bzxicCB6fRlwK3AGf0XSh9NuzXJUwhLLajXzMyaVGt03C8PUA5ARDQz7MjWEbEs3c4ySVtVqWc94NvAx4CDam1M0hRgCsDYsWObCMvMzAZT64xjk/R1Z2AvYEY6fyRw+2AblnQz8OYqb52dMbaTgRsi4olyshpIREwFpgKUSqW/GQLezMxap9bouOcBSLoR2LPcRCXpXCpuCKyx/oDjWUlaLml0erYxGniyymL7AO+RdDLwRmADSS9ERK3+EDMzy1mWZ46PBV6tmH8VGNdkvTOAE4AL0tfp/ReIiH8oT0s6ESg5aZiZdV6WxHEFcLek60guyT2apEO7GRcAP5f0KeDPwDEAkkrAZyPipCa3b2ZmOVHE4F0CkvYE3pPO3h4R9+QaVRNKpVL09fV1OgwzsyFF0pyIyHT1apYzDiJiLjC3qajMzKwrZLkB0MzM7HVOHGZmVpcsw6r/ryxlZmbWG7KccRxSpez9rQ7EzMyGhlpDjnyO5O7t7SXNq3hrE+APeQdmZmbFVOuqqquA3wDfZN3Ra1dGxLO5RmVmZoU1YFNVRDwXEY8B5wB/iYjHgfHARyWNbFN8ZmZWMFn6OH4JrJW0I3ApSfK4KteozMyssLIkjtciYg0wCbg4Ik4DRucblpmZFVWWxLFa0nHAx4FfpWXD8wvJzMyKLEvi+ATJEOffiIhHJY0HfpJvWGZmVlRZHh27UNIZJMOrExGPkoxua2ZmPSjLneNHAveSPPcbSe+QNKP2WmZm1q2yNFWdC+wNrACIiHtJrqwyM7MelCVxrImI5/qV+bneZmY9KsvzOBZIOh4YJmkCcApwR75hmZlZUWU54/gi8DbgFeBq4Hng1DyDMjOz4spyVdVLwNnpUOoRESvzD8vMzIoqy1VVe0maD8wD5ku6T9I78w/NzMyKKEsfx6XAyRHxHwCS9gd+DOyeZ2BmZlZMWfo4VpaTBkBE/B5wc5WZWY+q9SCnPdPJuyX9gKRjPIDJwK35h2ZmZkVUq6nq2/3m/7li2vdxmJn1qAETR0S8t52BmJnZ0JClj8PMzOx1HUkckraQdJOkh9LXzQdYbqykGyU9IGmhpHHtjdTMzPobMHFIOiZ9zWNAwzOBWRExAZiVzldzOXBRRLyVZKDFJ3OIxczM6lDrjOOs9PWXOdQ7Ebgsnb4MOKr/ApJ2BdaPiJsAIuKF9C52MzProFpXVT0j6RZgfLXnb0TEh5qod+uIWJZuZ5mkraossxOwQtK1JMO43wycGRFr+y8oaQowBWDs2LFNhGVmZoOplTg+COwJXMHfXpo7KEk3A2+u8tbZGTexPvAeYA/gz8DPgBNJ7mRfR0RMBaYClEolXypsZpajWpfjvgrcJWnfiHhK0iZJcbyQZcMRcfBA70laLml0erYxmup9F4uBeyJiUbrONODdVEkcZmbWPlmuqtpa0j3AAmChpDmS3t5kvTOAE9LpE4DpVZaZDWwuaVQ6/z5gYZP1mplZk7IkjqnAlyPiLRExFvjHtKwZFwCHSHoIOCSdR1JJ0iUAaV/GV4BZ6ei8An7YZL1mZtakLKPjbhwRt5RnIuJWSRs3U2lEPAMcVKW8DzipYv4mPAqvmVmhZEkciyR9naSTHOCjwKP5hWRmZkWWpanqk8Ao4Nr0b0vgE3kGZWZmxZXl0bF/BU5pQyxmZjYEeJBDMzOrixOHmZnVxYnDzMzqMmjikLSTpFmSFqTzu0s6J//QzMysiLKccfyQZKTc1QARMQ84Ns+gzMysuLIkjjdExN39ytbkEYyZmRVflsTxtKQdgACQ9GFgWa5RmZlZYWW5c/zzJGNT7SJpCcld4x/NNSozMyusLDcALgIOTsenWi8iVuYflpmZFdWgiUPSP/WbByAizs8pJjMzK7AsTVUvVkxvBBwBPJBPOGZmVnRZmqrWeWyspG+RPIjJzMx6UCN3jr8B2L7VgZiZ2dCQpY9jPumluMAwkiHW3b9hZtajsvRxHFExvQZYHhG+AdDMrEcNmDgkbZFO9r/8dlNJRMSz+YVlZmZFVeuMYw5JE5WqvBe4n8PMrCcNmDgiYnw7AzEzs6EhSx8HkjYHJpDcxwFARNyeV1BmZlZcWa6qOgn4ErAtcC/wbuBO4H35hmZmZkWU5T6OLwF7AY9HxHuBPYCnco3KzMwKK0vieDkiXgaQtGFE/BHYOd+wzMysqLIkjsWSRgLTgJskTQeWNlOppC0k3STpofR18wGWu1DS/ZIekPR/VR5h0czMOmbAxCHpK5K2i4ijI2JFRJwLfB24FDiqyXrPBGZFxARgVjrfv/59gf2A3YG3kzSX/X2T9ZqZWZNqdY6PAe6Q9ChwNXBNRNzWononAgem05cBtwJn9FsmSK7i2oDkXpLhwPIW1W9mZg0a8IwjIk4DxpKcZewOzJP0G0kfl7RJk/VuHRHL0nqWAVtVqf9O4BaSx9QuA2ZGRNXh3CVNkdQnqe+pp9xvb2aWp5p9HJG4LSI+B2wHXAycRob/+Uu6WdKCKn8TswQmaUfgrSSXAY8B3ifpgAHinBoRpYgojRo1KsvmzcysQVlvANwNOBaYDDwDfG2wdSLi4BrbWy5pdEQskzQaeLLKYkcDd0XEC+k6vyG5h8Q3HpqZdVCtzvEJkr4uaSFwFfAScGhEvCsiLm6y3hnACen0CcD0Ksv8Gfh7SetLGk7SMe4nD5qZdVitpqqZJJ3TkyNit4j4RkQsalG9FwCHSHoIOCSdR1JJ0iXpMr8AHgHmA/cB90XE9S2q38zMGlRrkMPcRr+NiGeAg6qU9wEnpdNrgc/kFYOZmTWmkUfHmplZD3PiMDOzugyaOCR9KUuZmZn1hixnHCdUKTuxxXGYmdkQUeuZ48cBxwPjJc2oeGsTkns5zMysB9W6AfAOkqE+tgS+XVG+EpiXZ1BmZlZctS7HfRx4HNinfeGYmVnRZekcn5Q+N+M5Sc9LWinp+XYEZ2ZmxZNlrKoLgSMHGpnWzMx6S5arqpY7aZiZWVmWM44+ST8jeXTsK+XCiLg2t6jMzKywsiSOTUlHxq0oC8CJw8ysBw2aOCLiE+0IxMzMhoZaNwB+NSIulPRdkjOMdUTEKblGZmZmhVTrjKPcId7XjkDMzGxoqHUD4PXp62XtC8fMzIpu0D4OSaOAM4BdSZ4ICEBEvC/HuMzMrKCy3MdxJUmz1XjgPOAxYHaOMZmZWYFlSRxviohLgdURcVtEfBJ4d85xmZlZQWW5j2N1+rpM0geBpcC2+YVkZmZFliVx/E9JmwH/CHyX5IbA03KNyszMCqtm4pA0DJgQEb8CngPe25aozMyssGr2cUTEWuBDbYrFzMyGgCxNVXdI+h7wM+DFcmFEzM0tKjMzK6wsiWPf9PX8irIAfB+HmVkPynI57qci4r2Vf8BJzVQq6RhJ90t6TVKpxnKHS3pQ0sOSzmymTjMza40sieMXVcquabLeBcAk4PaBFkg75v8f8H6Su9aPk7Rrk/WamVmTao2OuwvwNmAzSZMq3tqUiqFHGlF+oqCkWovtDTwcEYvSZX8KTAQWNlO3mZk1p1Yfx87AEcBI4MiK8pXAp/MMKjUGeKJifjHwrjbUa2ZmNdQaHXc6MF3SPhFxZ70blnQz8OYqb52dbnvQTVQLa4C6pgBTAMaOHZs5RjMzq1+Wq6qOlnQ/sAr4LfB3wKkR8ZNaK0XEwU3GthjYrmJ+W5LhTqrVNRWYClAqlaomFzMza40sneOHRsTzJM1Wi4GdgNNzjSoxG5ggabykDYBjgRltqNfMzGrIkjiGp68fAK6OiGebrVTS0ZIWA/sAv5Y0My3fRtINABGxBvgCMJNkWPefR8T9zdZtZmbNydJUdb2kP5I0VZ2cPtjp5WYqjYjrgOuqlC8lSVDl+RuAG5qpy8zMWmvQM46IOJPkzKAUEatJhh2ZmHdgZmZWTFnOOADeCoyTVLn85TnEY2ZmBZflmeNXADsA9wJr0+LAicPMrCdlOeMoAbtGhC9zNTOzTFdVLaD6jXxmZtaDspxxbAkslHQ38Eq5MCL8gCczsx6UJXGcm3cQZmY2dAyaOCLiNklbA3ulRXdHxJP5hmVmZkU1aB+HpI8AdwPHAB8B/lPSh/MOzMzMiilLU9XZwF7ls4z0zvGbqf6AJzMz63JZrqpar1/T1DMZ1zMzsy6U5Yzjt+kghFen85OB3+QXkpmZFVmWzvHT00fH7k/ycKWp6SCFZmbWg2o9c3xHYOuI+ENEXAtcm5YfIGmHiHikXUGamVlx1OqruJjk+eL9vZS+Z2ZmPahWU9W4iJjXvzAi+iSNyy0iG3Km3bOEi2Y+yNIVq9hm5AhOP2xnjtpjTKfDsiGmG4+jbvxMUDtxbFTjvRGtDsSGpmn3LOGsa+ezanUycPKSFas469r5ALn8QLr1h9jr2n0ctUM3fqayWk1VsyV9un+hpE8Bc/ILyYaSi2Y++PoPo2zV6rVcNPPBltdV/iEuWbGK4L9/iNPuWdLyuqy92nkctUs3fqayWmccpwLXSfoH/jtRlIANgKPzDsyGhqUrVtVV3oxaP8Sh/j+4XtfO46hduvEzlQ14xhERyyNiX+A84LH077yI2Cci/tKe8KzothlZvdVyoPJmdPMPsde18zhql278TGVZnjl+S0R8N/37XTuCsqHj9MN2ZsTwYeuUjRg+jNMP27nldXXzD7HXtfM4apdu/ExlHjrEmnLUHmP45qTdGDNyBALGjBzBNyftlkvTUTf/EHtdO4+jdunGz1SmbnsibKlUir6+vk6HYTnxVVVm+ZA0JyJKWZbNMlaVWWEctccYJwqzDnNTlZmZ1cWJw8zM6uLEYWZmdXHiMDOzujhxmJlZXbruclxJTwGPA1sCT3c4nKLwvkh4PyS8HxLeD4nyfnhLRIzKskLXJY4ySX1Zr0nudt4XCe+HhPdDwvsh0ch+cFOVmZnVxYnDzMzq0s2JY2qnAygQ74uE90PC+yHh/ZCoez90bR+HmZnlo5vPOMzMLAdOHGZmVpeuTBySDpf0oKSHJZ3Z6Xg6RdJjkuZLuldST401L+lHkp6UtKCibAtJN0l6KH3dvJMxtsMA++FcSUvS4+JeSR/oZIztIGk7SbdIekDS/ZK+lJb31DFRYz/UdUx0XR+HpGHAn4BDgMXAbOC4iFjY0cA6QNJjQCkieu4mJ0kHAC8Al0fE29OyC4FnI+KC9D8Um0fEGZ2MM28D7IdzgRci4ludjK2dJI0GRkfEXEmbAHOAo4AT6aFjosZ++Ah1HBPdeMaxN/BwRCyKiFeBnwITOxyTtVlE3A482694InBZOn0ZyQ+mqw2wH3pORCyLiLnp9ErgAWAMPXZM1NgPdenGxDEGeKJifjEN7JguEcCNkuZImtLpYApg64hYBskPCNiqw/F00hckzUubsrq6eaY/SeOAPYD/pIePiX77Aeo4JroxcahKWXe1x2W3X0TsCbwf+HzabGH2b8AOwDuAZcC3OxtO+0h6I/BL4NSIeL7T8XRKlf1Q1zHRjYljMbBdxfy2wNIOxdJREbE0fX0SuI6kGa+XLU/beMttvU92OJ6OiIjlEbE2Il4DfkiPHBeShpP8Y3llRFybFvfcMVFtP9R7THRj4pgNTJA0XtIGwLHAjA7H1HaSNk47v5C0MXAosKD2Wl1vBnBCOn0CML2DsXRM+R/K1NH0wHEhScClwAMR8Z2Kt3rqmBhoP9R7THTdVVUA6aVkFwPDgB9FxDc6HFLbSdqe5CwDYH3gql7aD5KuBg4kGTJ6OfDPwDTg58BY4M/AMRHR1R3HA+yHA0maJAJ4DPhMuZ2/W0naH/gPYD7wWlr8NZL2/Z45Jmrsh+Oo45joysRhZmb56camKjMzy5ETh5mZ1cWJw8zM6uLEYWZmdXHiMDOzujhxWFeQ9EL6Ok7S8S3e9tf6zd/Rou3+ezoi6Ybp/JbpwJSt2PaBkn7Vim2Z9efEYd1mHFBX4khHVK5lncQREfvWGVMta4FPtnB7LZFhn1gPc+KwbnMB8J70mQKnSRom6SJJs9MB3D4Dr/+P/BZJV5HcDIWkaemAkPeXB4WUdAEwIt3elWlZ+exG6bYXpM89mVyx7Vsl/ULSHyVdmd6xW83FwGmS1q8s7H/GIOl7kk5Mpx+T9K+S7pTUJ2lPSTMlPSLpsxWb2VTSdZIWSvq+pPXS9Q9N150r6Zp03KLydv9J0u+BY5r5Eqy7rT/4ImZDypnAVyLiCIA0ATwXEXulTUJ/kHRjuuzewNsj4tF0/pMR8aykEcBsSb+MiDMlfSEi3lGlrkkkd9v+Hcmd2bMl3Z6+twfwNpJx0v4A7Af8vso2/pyWfwy4vo7P+URE7CPpfwP/nm5/I+B+4PsVn29X4HHgt8AkSbcC5wAHR8SLks4Avgycn67zckTsX0cc1oOcOKzbHQrsLunD6fxmwATgVeDuiqQBcIqko9Pp7dLlnqmx7f2BqyNiLclgebcBewHPp9teDCDpXpImtGqJA+BfScZM+nUdn6s8/tp84I3psxVWSnpZ0sj0vbsjYlEaw9VpvC+TJJM/pCdBGwB3Vmz3Z3XEYD3KicO6nYAvRsTMdQqlA4EX+80fDOwTES+l/zPfKMO2B/JKxfRaavzWIuLhNLl8pKJ4Des2JfePpbz91/rV9VpFXf3HE4o05psi4rgBwnlxgHKz17mPw7rNSmCTivmZwOfSoaSRtFM6WnB/mwF/TZPGLsC7K95bXV6/n9uByWk/yijgAODuBuP+BvCVivnHgV0lbShpM+CgBra5dzpK9HrAZJIznruA/STtCCDpDZJ2ajBm61FOHNZt5gFrJN0n6TTgEmAhMFfSAuAHVP/f/2+B9SXNA/6F5B/YsqnAvHLneIXr0vruA34HfDUi/tJI0BFxPzC3Yv4JklFb5wFXAvc0sNk7SS4WWAA8ClwXEU+RPGf76vSz3gXs0kjM1rs8Oq6ZmdXFZxxmZlYXJw4zM6uLE4eZmdXFicPMzOrixGFmZnVx4jAzs7o4cZiZWV3+C0cZK5KgeKlrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEST PROBLEM\n",
    "## Don't show warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nx_dim = 1\n",
    "x_range = [[0, 1.2]] # in units\n",
    "\n",
    "n_gt = 10 # number of design samples used to train the ground truth GP\n",
    "n_f1 = 40 # number of design samples used to train the analytical model GP\n",
    "n_f2 = 40 # number of design smaples used to train the neural network GP\n",
    "n_fs = [n_f1, n_f2]\n",
    "\n",
    "n_c_gt = 10 # number of design samples used to train the constraint ground truth GP\n",
    "n_const1 = 40 # number of design smaples used to train the first lower fidelity constraint GP\n",
    "n_const2 = 40 # number of design smaples used to train the second lower fidelity constraint GP\n",
    "n_cs = [n_const1, n_const2]\n",
    "\n",
    "n_test = 50 # number of design samples used to fuse GPs\n",
    "n_alt = 30 # number of candidate designs to sample in each iteration\n",
    "\n",
    "cost_gt_f = 100 # cost of evaluating a design using high fidelity model\n",
    "cost_f1 = 25 # cost of evaluating a design using low fidelity model 1\n",
    "cost_f2 = 20 # cost of evaluating a design using low fidelity model 2\n",
    "cost_fs = [cost_gt_f, cost_f1, cost_f2]\n",
    "\n",
    "cost_gt_c = 40 # cost of evaluating constraint for a design using ground truth \n",
    "cost_c1 = 10 # cost of evaluating constraint for a design using lower fidelity model 1\n",
    "cost_c2 = 5 # cost of evaluating constraint for a design using lower fidelity model 2\n",
    "cost_cs = [cost_gt_c, cost_c1, cost_c2]\n",
    "\n",
    "max_cost = 5000 # stopping criterion in seconds\n",
    "vf_lim = 0.1 # not useful here but provided as a required input to the optimization function\n",
    "prob = 'test'\n",
    "\n",
    "x_best_dict, y_best_vec, y_best_std_vec, c_best_vec, c_best_std_vec, cost_vec = MFCBO(nx_dim, x_range, n_gt, n_fs, n_c_gt, n_cs, n_alt, n_test, cost_fs, cost_cs, max_cost, vf_lim, prob)     \n",
    "\n",
    "## Plot the Best Function Values by iteration number\n",
    "n_iterations = len(y_best_vec)\n",
    "x_iter = np.linspace(1, n_iterations, n_iterations)\n",
    "y_cb = [3*i for i in y_best_std_vec]\n",
    "fig1 = plt.figure()\n",
    "plt.errorbar(x_iter, y_best_vec, yerr=y_cb, fmt='o')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Best Function Value in units')\n",
    "plt.show()\n",
    "fig1.savefig('ybest_vs_iter_test.png')\n",
    "\n",
    "## Plot the Constraint Values of the best design by iteration number\n",
    "fig2 = plt.figure()\n",
    "c_cb = [3*i for i in c_best_std_vec]\n",
    "plt.errorbar(x_iter, c_best_vec, yerr=c_cb, fmt='o')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Constraint Value of best design in units')\n",
    "plt.show()\n",
    "fig2.savefig('c_best_vs_iter_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1\n",
      "Initialization complete\n",
      "Infeasible designs filtered\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-18ca0bbc6be9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'composite_plate'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mx_best_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_best_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_best_std_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_best_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_best_std_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMFCBO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_gt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_c_gt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_cs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_alt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_fs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_cs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvf_lim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m## Plot the Best Function Values by iteration number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-4ba729b9c312>\u001b[0m in \u001b[0;36mMFCBO\u001b[1;34m(n_xvar, x_range, n_gt, n_f, n_const_gt, n_const, n_alt, n_test, cost_f, cost_c, max_cost, vf_limit, problem)\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[0mcost_f_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[0mutility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEi_f\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcost_f_j\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m             \u001b[0mEi_f_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[0mEi_f_argmax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[0mis_query_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEi_f_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\msen_655\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2666\u001b[0m     \"\"\"\n\u001b[0;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2668\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\msen_655\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "### COMPOSITE PLATE PROBLEM\n",
    "## Don't show warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "l = 3048 # length of composite plate in mm\n",
    "w = 3048 # width of composite plate in mm\n",
    "t = 254 # thickness of composite plate in mm\n",
    "E_f = 121 # Young's Modulus of fibre in GPa (same as abaqus fea, this is the Young's Modulus of Copper)\n",
    "\n",
    "nx_dim = 3\n",
    "rf_range = [25, (t/2)-20] # in mm\n",
    "thetaf_range = [0, 90] # in degrees\n",
    "Em_range = [10, 800] # in GPa \n",
    "x_range = np.vstack((rf_range, thetaf_range, Em_range))\n",
    "\n",
    "n_test = 150 # number of design samples used to fuse GPs\n",
    "n_alt = 100 # number of candidate designs to sample in each iteration\n",
    "\n",
    "n_gt = 10 # number of design samples used to train the ground truth GP\n",
    "n_f1 = 50 # number of design samples used to train the analytical model GP\n",
    "n_f2 = 50 # number of design smaples used to train the neural network GP\n",
    "n_fs = [n_f1, n_f2]\n",
    "\n",
    "n_c_gt = 10 # number of design samples used to train the ground truth constraint GP\n",
    "n_const1 = 50 # number of design samples used to train the first lower fidelity constraint GP\n",
    "n_const2 = 50 # number of design samples used to train the second lower fidelity constraint GP\n",
    "n_cs = [n_const1, n_const2]\n",
    "\n",
    "cost_gt_f = 2000 # cost of evaluating a design using abaqus fea model \n",
    "cost_f1 = 50 # cost of evaluating a design using analytical model \n",
    "cost_f2 = 30 # cost of evaluating a design using neural network \n",
    "cost_fs = [cost_gt_f, cost_f1, cost_f2]\n",
    "\n",
    "cost_gt_c = 100 # cost of evaluating constraint for a design using ground truth \n",
    "cost_c1 = 20 # cost of evaluating constraint for a design using lower fidelity model 1\n",
    "cost_c2 = 10 # cost of evaluating constraint for a design using lower fidelity model 2\n",
    "cost_cs = [cost_gt_c, cost_c1, cost_c2]\n",
    "\n",
    "max_cost = 40000 # stopping criterion in seconds\n",
    "vf_lim = 0.75 # constraint limit\n",
    "prob = 'composite_plate'\n",
    "\n",
    "x_best_dict, y_best_vec, y_best_std_vec, c_best_vec, c_best_std_vec, cost_vec = MFCBO(nx_dim, x_range, n_gt, n_fs, n_c_gt, n_cs, n_alt, n_test, cost_fs, cost_cs, max_cost, vf_lim, prob)     \n",
    "\n",
    "## Plot the Best Function Values by iteration number\n",
    "n_iterations = len(y_best_vec)\n",
    "x_iter = np.linspace(1, n_iterations, n_iterations)\n",
    "y_cb = [3*i for i in y_best_std_vec]\n",
    "fig1 = plt.figure()\n",
    "plt.errorbar(x_iter, y_best_vec, yerr=y_cb, fmt='o')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Maximum Effective Buckling Load in N/mm^2')\n",
    "plt.show()\n",
    "fig1.savefig('ybest_vs_iter_compplate.png')\n",
    "\n",
    "## Plot the Constraint Values of the best design by iteration number\n",
    "fig2 = plt.figure()\n",
    "c_cb = [3*i for i in c_best_std_vec]\n",
    "plt.plot(x_iter, c_best_vec, yerr=c_cb, fmt='o')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Constraint Value of best design')\n",
    "plt.show()\n",
    "fig2.savefig('c_best_vs_iter_compplate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
